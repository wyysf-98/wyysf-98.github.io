<!DOCTYPE html>

<head>
    <meta charset="utf-8" />
    <title>Example-based Motion Synthesis via Generative Motion Matching</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="Example-based Motion Synthesis via Generative Motion Matching" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Example-based Motion Synthesis via <br> Generative Motion Matching</h1>
            <div class="nerf_subheader_v2">ACM Transactions on Graphics (SIGGRAPH 2023)</div>
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://wyysf-98.github.io/" target="_blank" class="nerf_authors_v2">Weiyu Li<span
                            class="text-span_nerf"></span></a><sup>*1</sup>,&nbsp;&nbsp;
                    <a href="https://xuelin-chen.github.io/" target="_blank" class="nerf_authors_v2">Xuelin Chen<span
                            class="text-span_nerf"></span></a><sup>*â€ 2</sup>,&nbsp;&nbsp;
                    <a href="https://peizhuoli.github.io/" target="_blank" class="nerf_authors_v2">Peizhuo Li<span
                            class="text-span_nerf"></span></a><sup>3</sup>,&nbsp;&nbsp;
                    <a href="https://igl.ethz.ch/people/sorkine/" target="_blank" class="nerf_authors_v2">Olga Sorkine-Hornung<span
                            class="text-span_nerf"></span></a><sup>3</sup>,&nbsp;&nbsp;
                    <a href="https://cfcs.pku.edu.cn/baoquan/" target="_blank" class="nerf_authors_v2">Baoquan Chen<span
                            class="text-span_nerf"></span></a><sup>4</sup>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1</sup>Shandong University</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2</sup>Tencent AI Lab</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>3</sup>ETH Zurich</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>4</sup>Peking University</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://arxiv.org/abs/2306.00378" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/Paper_high_res.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="https://weiyuli.xyz/GenMM_demo/" role="button" target="_blank">
                        <i class="fas fa-democrat"></i> Demo </a>
                    <a class="btn" href="https://github.com/wyysf-98/GenMM" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn btn-large btn-light" href="https://youtu.be/lehnxcade4I" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>

            </div>
            <div>
                <h2 style="overflow: hidden">
                    <embed src="https://weiyuli.xyz/GenMM_demo/" width="100%" height="500">
                </h2>
                <p align="left">
                    1. FBX parser in Three.js is not robust and lacks foot contact fix in the demo, may produce artifacts. Wait for Blender addon for better performance.
                    <br>
                    2. The demo is powered by ðŸ¤—<a href="https://huggingface.co/spaces/wyysf/GenMM" class="nerf_authors_v2">Hugging Face</a> using CPU, 
                    which requires time for data transmission and multiple simultaneous uses may get stuck.
                    <br>
                    3. Click 'Next' to try more examples from <a href="https://www.mixamo.com/#/" class="nerf_authors_v2">Mixamo</a><a href="https://www.adobe.com/legal/terms.html" class="nerf_authors_v2">Â©</a>. 
                    See <a href="https://github.com/wyysf-98/GenMM_demo" class="nerf_authors_v2">more instructions</a> if any <b>problem</b> and have fun :)
                </p>
            </div>
        </div>

    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                We present <b style="color: rgb(124, 196, 245);">GenMM</b>, a generative model that "mines" as many diverse 
                motions as possible from a single or few example sequences. In stark contrast to existing data-driven methods, 
                which typically require long offline training time, are prone to visual artifacts, and tend to fail on large 
                and complex skeletons, GenMM inherits the <b style="color: rgb(124, 196, 245);">training-free nature</b> and 
                the <b style="color: rgb(124, 196, 245);">superior quality</b> of the well-known Motion Matching method. GenMM 
                can synthesize a high-quality motion within a fraction of a second, even with <b style="color: rgb(124, 196, 245);">
                highly complex and large</b> skeletal structures. 
                <br>
                <img  src="assets/images/overview.png">
                At the heart of our generative framework lies the generative motion matching module, 
                which utilizes the bidirectional visual similarity as a generative cost function to motion matching,
                and operates in a multi-stage framework to progressively refine a random guess using exemplar motion matches. 
            </p>
        </div>
    </div>


    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Novel Motion Synthesis</h2>
        <p class="paragraph-3 nerf_text sub_heading" style="color: rgb(124, 196, 245); margin-bottom: -10px;">
            <strong>* Blue border</strong> indicates the input motion sequence.
        </p>
        <p class="paragraph-3 nerf_text nerf_results_text">
            From a single example, our framework generates, within a second, diverse motion sequences for even highly complex 
            and large skeletons, including the animation of the clothes and eyes.
        </p>
        <div class="grid-container-2-text">
            <div style="text-align: center">Input</div>
            <div style="text-align: center">Synthesized motion</div>
        </div>
        <div class="grid-container">
            <div class="grid-item item1"><img src="assets/images/skeleton.png"></div>
            <!-- <div class="grid-item item2"><video class="video" style="border: 2px solid rgb(124, 196, 245);" loop playsinline autoPlay muted src="assets/videos/random_generation/gt_all.webm"></video></div> -->
            <div class="grid-item item2"><video class="video" id="video1" loop playsinline autoPlay muted src="assets/videos/random_generation/gt_bvh.webm"></video></div>
            <div class="grid-item item3"><video class="video" loop playsinline autoPlay muted src="assets/videos/random_generation/s73817.webm"></video></div>
            <div class="grid-item item4"><video class="video" loop playsinline autoPlay muted src="assets/videos/random_generation/s112706.webm"></video></div>
            <div class="grid-item item5"><video class="video" id="video2" style="border: 2px solid rgb(124, 196, 245);" loop playsinline autoPlay muted src="assets/videos/random_generation/gt.webm"></video></div>
            <div class="grid-item item6"><video class="video" loop playsinline autoPlay muted src="assets/videos/random_generation/s79170.webm"></video></div>
            <div class="grid-item item7"><video class="video" loop playsinline autoPlay muted src="assets/videos/random_generation/s332104.webm"></video></div>
          </div>
          <script>
            const video1 = document.getElementById("video1");
            const video2 = document.getElementById("video2");

            video1.addEventListener("play", syncVideos);
            video1.addEventListener("pause", syncVideos);
            video1.addEventListener("seeked", syncVideos);

            video2.addEventListener("play", syncVideos);
            video2.addEventListener("pause", syncVideos);
            video2.addEventListener("seeked", syncVideos);

            function syncVideos(event) {
            const target = event.target;

            if (target === video1) {
                if (video1.paused && !video2.paused) {
                video2.pause();
                } else if (!video1.paused && video2.paused) {
                video2.play();
                }

                if (Math.abs(video1.currentTime - video2.currentTime) > 0.1) {
                video2.currentTime = video1.currentTime;
                }
            } else if (target === video2) {
                if (video2.paused && !video1.paused) {
                video1.pause();
                } else if (!video2.paused && video1.paused) {
                video1.play();
                }

                if (Math.abs(video2.currentTime - video1.currentTime) > 0.1) {
                video1.currentTime = video2.currentTime;
                }
            }
            }
          </script>
    </div>

    
    
    <div class="white_section_nerf grey_container w-container">
        <h2 class="grey-heading_nerf">Applications</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            <b>Motion Completion.</b> Users can provide the <b style="color: rgb(235, 203, 97);">lower-body</b> motion and our method completes with diverse motions.
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">Input</div>
            <div style="text-align: center">Synthesized motion 1</div>
            <div style="text-align: center">Synthesized motion 2</div>
            <div style="text-align: center">Synthesized motion 3</div>
        </div>
        <div class="grid-container-4">
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/motion_completion/gt.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/motion_completion/s504630.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/motion_completion/s504640.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/motion_completion/s504636.webm"></video>
        </div>
        <p class="paragraph-3 nerf_text nerf_results_text">
            <b>Key Frame-guided Generation.</b> We can generate diverse novel motion sequence that follow the user given key frame poses. 
            <div id="controls">
                <div id="progress-bar" onclick="seek(event)">
                    <div id="progress"></div>
                    <div id="progress-bar-marker1"></div>
                    <div id="progress-bar-marker2"></div>
                </div>
                <span id="frame-count">0</span>
                <button id="play-pause">Pause</button>
            </div>
            <div class="grid-container-4-text">
                <div style="text-align: center">Input</div>
                <div style="text-align: center">Synthesized motion 1</div>
                <div style="text-align: center">Synthesized motion 2</div>
                <div style="text-align: center">Synthesized motion 3</div>
            </div>
            <div class="grid-container-4">
                <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/keyframe/gt_fbx_add_floor.webm"></video>
                <video id="keyframe1" class="video" loop playsinline autoPlay muted src="assets/videos/keyframe/s403195.webm"></video>
                <video id="keyframe2" class="video" loop playsinline autoPlay muted src="assets/videos/keyframe/s403523.webm"></video>
                <video id="keyframe3" class="video" loop playsinline autoPlay muted src="assets/videos/keyframe/s403228.webm"></video>
            </div>
        </p>
        <script>
            const videos = [
                document.getElementById('keyframe1'),
                document.getElementById('keyframe2'),
                document.getElementById('keyframe3')
            ];
            const playPauseButton = document.getElementById('play-pause');
            const progressBar = document.getElementById('progress-bar');
            const progress = document.getElementById('progress');
            const frameCount = document.getElementById('frame-count');
    
            playPauseButton.addEventListener('click', () => {
                videos.forEach(video => {
                    if (video.paused) {
                        video.play();
                        playPauseButton.textContent = 'Pause';
                    } else {
                        video.pause();
                        playPauseButton.textContent = 'Play';
                    }
                });
            });
    
            const video = document.getElementById('keyframe1');
            video.addEventListener('timeupdate', () => {
                const percentage = (video.currentTime / video.duration) * 100;
                progress.style.width = percentage + '%';
                frameCount.textContent = Math.round(video.currentTime * video.playbackRate * 30);
            });
    
            function seek(event) {
                const offsetX = event.clientX - progressBar.getBoundingClientRect().left;
                const percentage = offsetX / progressBar.clientWidth;
                videos.forEach(video => {
                    video.currentTime = percentage * video.duration;
                });
            }
        </script>

        <p class="paragraph-3 nerf_text nerf_results_text">
            <b>Infinite Looping.</b> By simply specifying the starting and ending pose to be identical, we can generate a infinitely looping animation. 
        </p>
        <div class="grid-container-3-text">
            <div style="text-align: center">Synthesized motion</div>
            <div style="text-align: center">Synthesized motion</div>
            <div style="text-align: center">Synthesized motion</div>
        </div>
        <div class="grid-container-3">
            <video class="video" id="crab-looping" loop playsinline autoPlay muted src="assets/videos/looping/crab-s357662.webm"></video>
            <video class="video" id="dragon-looping" loop playsinline autoPlay muted src="assets/videos/looping/dragon-s158621.webm"></video>
            <video class="video" id="ch20-looping" loop playsinline autoPlay muted src="assets/videos/looping/Ch20-s157823.webm"></video>
        </div>

        <p class="paragraph-3 nerf_text nerf_results_text">
            <b>Motion Reassembly.</b> Given two motion sequences with heterogeneous skeletons, our method can combine them to form a new creature with coherent and natural motion.
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">Character 1</div>
            <div style="text-align: center">Character 2</div>
            <div style="text-align: center">Synthesized motion 1</div>
            <div style="text-align: center">Synthesized motion 2</div>
        </div>
        <div class="grid-container-4">
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/motion_reassembly/c1.webm"></video>
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/motion_reassembly/c2.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/motion_reassembly/s597288.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/motion_reassembly/s597427.webm"></video>
        </div>
        <p class="paragraph-3 nerf_text nerf_results_text">
            <b>Locomotion.</b> When a locolotion is given as input, our framework can generate high-quality output with a different trajectory.
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">Input trajectory</div>
            <div style="text-align: center">Input</div>
            <div style="text-align: center">Synthesized trajectory</div>
            <div style="text-align: center">Synthesized motion</div>
        </div>
        <div class="grid-container-4">
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/locomotion/traj-gt.webm"></video>
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/locomotion/walk-gt.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/locomotion/traj-syn.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/locomotion/walk-syn.webm"></video>
        </div>
    </div>



    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Comparisons & Ablation</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            We compare our generated results to classic and state-of-the-art techniques that can use a single input sequence. 
            Our method outperforms these methods with diverse and high-quality results, where highly dynamic motions are well preserved. 
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">Input</div>
            <div style="text-align: center">MotionTexture</div>
            <div style="text-align: center">GANimator</div>
            <div style="text-align: center">Ours</div>
        </div>
        <div class="grid-container-4">
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/comparisons/gt.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/comparisons/motiontexture.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/comparisons/ganimator.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/comparisons/ours.webm"></video>
        </div>
        <p class="paragraph-3 nerf_text nerf_results_text">
            GANimator struggles to incorporate all examples, resulting in the loss of a significant portion of exemplar motion patches in the synthesis. 
            In contrast, our method effectively covers all examples, resulting in high coverage score.
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">GANimator</div>
            <div style="text-align: center">Coverage of GANimator</div>
            <div style="text-align: center">Ours</div>
            <div style="text-align: center">Coverage of Ours</div>
        </div>
        <div class="grid-container-4">
            <video class="video" loop playsinline autoPlay muted src="assets/videos/completeness/ganimator.webm"></video>
            <img  src="assets/images/ganimator_coverage.png">
            <video class="video" loop playsinline autoPlay muted src="assets/videos/completeness/ours.webm"></video>
            <img  src="assets/images/ours_coverage.png">
        </div>
        <p class="paragraph-3 nerf_text nerf_results_text">
            Skeleton-aware motion patch extraction enables the generation of more diverse sequences, such as waving with one hand, 
            compared to only generating sequences with two hands waving simultaneously without it.
        </p>
        <div class="grid-container-4-text">
            <div style="text-align: center">Input</div>
            <div style="text-align: center">w/o skeleton-aware</div>
            <div style="text-align: center">w/ skeleton-aware</div>
            <div style="text-align: center">w/ skeleton-aware</div>
        </div>
        <div class="grid-container-4">
            <video style="border: 2px solid rgb(124, 196, 245);" class="video" loop playsinline autoPlay muted src="assets/videos/skeleton-aware/gt.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/skeleton-aware/wo.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/skeleton-aware/s375928.webm"></video>
            <video class="video" loop playsinline autoPlay muted src="assets/videos/skeleton-aware/s376033.webm"></video>
        </div>
        <p class="paragraph-3 nerf_text nerf_results_text">
            [1]. Li, Yan, Tianshu Wang, and Heung-Yeung Shum. "Motion texture: a two-level statistical model for character motion synthesis." Proceedings of the 29th annual conference on Computer graphics and interactive techniques. 2002.
        </p>
            
    </div>
    <div class="white_section_nerf grey_container w-container">
        <h2 class="grey-heading_nerf">BibTeX</h2>
        <div class="bibtex">
            <pre><code>@article{weiyu23GenMM,
    author    = {Weiyu Li and Xuelin Chen and Peizhuo Li and Olga Sorkine-Hornung and Baoquan Chen},
    title     = {Example-based Motion Synthesis via Generative Motion Matching},
    journal   = {ACM Transactions on Graphics (TOG)},
    year      = {2023},
    publisher = {ACM}
}</code></pre>
        </div>
    </div>

</body>
<footer>
    This project page is inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
</footer>

</html>